{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T06:52:02.056532Z",
     "iopub.status.busy": "2024-08-14T06:52:02.056169Z",
     "iopub.status.idle": "2024-08-14T06:52:03.531517Z",
     "shell.execute_reply": "2024-08-14T06:52:03.530946Z",
     "shell.execute_reply.started": "2024-08-14T06:52:02.056502Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import streamlit as st\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from typing import Any, List, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3：司法大模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 环境准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T06:36:02.267737Z",
     "iopub.status.busy": "2024-08-14T06:36:02.267382Z",
     "iopub.status.idle": "2024-08-14T06:36:04.890776Z",
     "shell.execute_reply": "2024-08-14T06:36:04.890156Z",
     "shell.execute_reply.started": "2024-08-14T06:36:02.267714Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: streamlit==1.24.0 in /usr/local/lib/python3.10/site-packages (1.24.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/site-packages (from streamlit==1.24.0) (5.3.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/site-packages (from streamlit==1.24.0) (1.8.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/site-packages (from streamlit==1.24.0) (5.4.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/site-packages (from streamlit==1.24.0) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/site-packages (from streamlit==1.24.0) (6.11.0)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/site-packages (from streamlit==1.24.0) (1.26.3)\n",
      "Requirement already satisfied: packaging<24,>=14.1 in /usr/local/lib/python3.10/site-packages (from streamlit==1.24.0) (23.2)\n",
      "Requirement already satisfied: pandas<3,>=0.25 in /usr/local/lib/python3.10/site-packages (from streamlit==1.24.0) (2.0.3)\n",
      "Requirement already satisfied: pillow<10,>=6.2.0 in /usr/local/lib/python3.10/site-packages (from streamlit==1.24.0) (9.5.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/site-packages (from streamlit==1.24.0) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=4.0 in /usr/local/lib/python3.10/site-packages (from streamlit==1.24.0) (12.0.0)\n",
      "Requirement already satisfied: pympler<2,>=0.9 in /usr/local/lib/python3.10/site-packages (from streamlit==1.24.0) (1.1)\n",
      "Requirement already satisfied: python-dateutil<3,>=2 in /usr/local/lib/python3.10/site-packages (from streamlit==1.24.0) (2.9.0.post0)\n",
      "Requirement already satisfied: requests<3,>=2.4 in /usr/local/lib/python3.10/site-packages (from streamlit==1.24.0) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.11.0 in /usr/local/lib/python3.10/site-packages (from streamlit==1.24.0) (13.7.1)\n",
      "Requirement already satisfied: tenacity<9,>=8.0.0 in /usr/local/lib/python3.10/site-packages (from streamlit==1.24.0) (8.5.0)\n",
      "Requirement already satisfied: toml<2 in /usr/local/lib/python3.10/site-packages (from streamlit==1.24.0) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.1 in /usr/local/lib/python3.10/site-packages (from streamlit==1.24.0) (4.12.0)\n",
      "Requirement already satisfied: tzlocal<5,>=1.1 in /usr/local/lib/python3.10/site-packages (from streamlit==1.24.0) (4.3.1)\n",
      "Requirement already satisfied: validators<1,>=0.2 in /usr/local/lib/python3.10/site-packages (from streamlit==1.24.0) (0.33.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3 in /usr/local/lib/python3.10/site-packages (from streamlit==1.24.0) (3.1.43)\n",
      "Requirement already satisfied: pydeck<1,>=0.1.dev5 in /usr/local/lib/python3.10/site-packages (from streamlit==1.24.0) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/site-packages (from streamlit==1.24.0) (6.4.1)\n",
      "Requirement already satisfied: watchdog in /usr/local/lib/python3.10/site-packages (from streamlit==1.24.0) (4.0.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit==1.24.0) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit==1.24.0) (4.23.0)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit==1.24.0) (0.12.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3->streamlit==1.24.0) (4.0.11)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/site-packages (from importlib-metadata<7,>=1.4->streamlit==1.24.0) (3.19.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas<3,>=0.25->streamlit==1.24.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/site-packages (from pandas<3,>=0.25->streamlit==1.24.0) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil<3,>=2->streamlit==1.24.0) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.4->streamlit==1.24.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.4->streamlit==1.24.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.4->streamlit==1.24.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.4->streamlit==1.24.0) (2024.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/site-packages (from rich<14,>=10.11.0->streamlit==1.24.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from rich<14,>=10.11.0->streamlit==1.24.0) (2.18.0)\n",
      "Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.10/site-packages (from tzlocal<5,>=1.1->streamlit==1.24.0) (0.1.0.post0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3->streamlit==1.24.0) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit==1.24.0) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.24.0) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.24.0) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.24.0) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.24.0) (0.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.11.0->streamlit==1.24.0) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# 安装 streamlit\n",
    "! pip install streamlit==1.24.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 模型下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T06:36:23.930420Z",
     "iopub.status.busy": "2024-08-14T06:36:23.930051Z",
     "iopub.status.idle": "2024-08-14T06:36:29.561970Z",
     "shell.execute_reply": "2024-08-14T06:36:29.561356Z",
     "shell.execute_reply.started": "2024-08-14T06:36:23.930395Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 向量模型下载\n",
    "from modelscope import snapshot_download\n",
    "model_dir = snapshot_download(\"AI-ModelScope/bge-small-zh-v1.5\", cache_dir='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-08-14T06:36:29.563806Z",
     "iopub.status.busy": "2024-08-14T06:36:29.563195Z",
     "iopub.status.idle": "2024-08-14T06:36:30.283465Z",
     "shell.execute_reply": "2024-08-14T06:36:30.282903Z",
     "shell.execute_reply.started": "2024-08-14T06:36:29.563773Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 源大模型下载\n",
    "from modelscope import snapshot_download\n",
    "# model_dir = snapshot_download('IEITYuan/Yuan2-2B-Mars-hf', cache_dir='.')\n",
    "model_dir = snapshot_download('IEITYuan/Yuan2-2B-July-hf', cache_dir='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 模型RAG实战"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T06:37:29.899348Z",
     "iopub.status.busy": "2024-08-14T06:37:29.899001Z",
     "iopub.status.idle": "2024-08-14T06:37:29.904778Z",
     "shell.execute_reply": "2024-08-14T06:37:29.904272Z",
     "shell.execute_reply.started": "2024-08-14T06:37:29.899326Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入所需的库\n",
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T06:37:34.282722Z",
     "iopub.status.busy": "2024-08-14T06:37:34.282360Z",
     "iopub.status.idle": "2024-08-14T06:37:34.288736Z",
     "shell.execute_reply": "2024-08-14T06:37:34.288053Z",
     "shell.execute_reply.started": "2024-08-14T06:37:34.282699Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义向量模型类\n",
    "class EmbeddingModel:\n",
    "    \"\"\"\n",
    "    class for EmbeddingModel\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path: str) -> None:\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "\n",
    "        self.model = AutoModel.from_pretrained(path).cuda()\n",
    "        print(f'Loading EmbeddingModel from {path}.')\n",
    "\n",
    "    def get_embeddings(self, texts: List) -> List[float]:\n",
    "        \"\"\"\n",
    "        calculate embedding for text list\n",
    "        \"\"\"\n",
    "        encoded_input = self.tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "        encoded_input = {k: v.cuda() for k, v in encoded_input.items()}\n",
    "        with torch.no_grad():\n",
    "            model_output = self.model(**encoded_input)\n",
    "            sentence_embeddings = model_output[0][:, 0]\n",
    "        sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n",
    "        return sentence_embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-08-14T06:37:39.389556Z",
     "iopub.status.busy": "2024-08-14T06:37:39.389197Z",
     "iopub.status.idle": "2024-08-14T06:37:40.339531Z",
     "shell.execute_reply": "2024-08-14T06:37:40.338925Z",
     "shell.execute_reply.started": "2024-08-14T06:37:39.389533Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Create embedding model...\n",
      "Loading EmbeddingModel from ./AI-ModelScope/bge-small-zh-v1___5.\n"
     ]
    }
   ],
   "source": [
    "print(\"> Create embedding model...\")\n",
    "embed_model_path = './AI-ModelScope/bge-small-zh-v1___5'\n",
    "embed_model = EmbeddingModel(embed_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T06:37:42.618322Z",
     "iopub.status.busy": "2024-08-14T06:37:42.617957Z",
     "iopub.status.idle": "2024-08-14T06:37:42.624762Z",
     "shell.execute_reply": "2024-08-14T06:37:42.624122Z",
     "shell.execute_reply.started": "2024-08-14T06:37:42.618300Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义向量库索引类\n",
    "class VectorStoreIndex:\n",
    "    \"\"\"\n",
    "    class for VectorStoreIndex\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, doecment_path: str, embed_model: EmbeddingModel) -> None:\n",
    "        self.documents = []\n",
    "        for line in open(doecment_path, 'r', encoding='utf-8'):\n",
    "            line = line.strip()\n",
    "            self.documents.append(line)\n",
    "\n",
    "        self.embed_model = embed_model\n",
    "        self.vectors = self.embed_model.get_embeddings(self.documents)\n",
    "\n",
    "        print(f'Loading {len(self.documents)} documents for {doecment_path}.')\n",
    "\n",
    "    def get_similarity(self, vector1: List[float], vector2: List[float]) -> float:\n",
    "        \"\"\"\n",
    "        calculate cosine similarity between two vectors\n",
    "        \"\"\"\n",
    "        dot_product = np.dot(vector1, vector2)\n",
    "        magnitude = np.linalg.norm(vector1) * np.linalg.norm(vector2)\n",
    "        if not magnitude:\n",
    "            return 0\n",
    "        return dot_product / magnitude\n",
    "\n",
    "    def query(self, question: str, k: int = 1) -> List[str]:\n",
    "        question_vector = self.embed_model.get_embeddings([question])[0]\n",
    "        result = np.array([self.get_similarity(question_vector, vector) for vector in self.vectors])\n",
    "        return np.array(self.documents)[result.argsort()[-k:][::-1]].tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T06:37:46.884718Z",
     "iopub.status.busy": "2024-08-14T06:37:46.884366Z",
     "iopub.status.idle": "2024-08-14T06:37:48.138772Z",
     "shell.execute_reply": "2024-08-14T06:37:48.138203Z",
     "shell.execute_reply.started": "2024-08-14T06:37:46.884694Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Create index...\n",
      "Loading 3 documents for ./knowledge.txt.\n"
     ]
    }
   ],
   "source": [
    "print(\"> Create index...\")\n",
    "doecment_path = './knowledge.txt'\n",
    "index = VectorStoreIndex(doecment_path, embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-08-14T06:41:00.898955Z",
     "iopub.status.busy": "2024-08-14T06:41:00.898596Z",
     "iopub.status.idle": "2024-08-14T06:41:00.906773Z",
     "shell.execute_reply": "2024-08-14T06:41:00.906201Z",
     "shell.execute_reply.started": "2024-08-14T06:41:00.898924Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Question: 2024年8月11日清晨，父亲与孩子以及自行车队在容城县南拒马河右堤附近的路段骑行。该路段尚未正式通车，但已成为当地居民晨骑的热门地点。在骑行过程中，12岁孩子骑行速度一度达到37公里/小时，并在骑行中喊出“慢一点”。不幸的是，在一次变道中孩子不慎摔倒，倒在了对面的机动车道上，随即遭到对向行驶的汽车碾压。涉事汽车的行车记录仪显示，事故发生时汽车的行驶速度约为52公里/小时。请分析该案件的责任方。\n",
      "> Context: ['郑州机械研究所有限公司（以下简称郑机所）的前身机械科学研究院1956年始建于北京，是原机械工业部直属一类综合研究院所，现隶属于国资委中国机械科学研究总院集团有限公司。郑机所伴随着共和国的成长一路走来，应运而生于首都，碧玉年华献中原。多次搬迁，驻地从北京经漯河再到郑州；数易其名，由机械科学研究院到漯河机械研究所再到郑州机械研究所，现为郑州机械研究所有限公司。1956～1958年应运而生：依据全国人大一届二次会议的提议和第一机械工业部的决策，1956年3月6日，第一机械工业部发文《（56）机技研究第66号》，通知“机械科学实验研究院”（后改名为“机械科学研究院”）在北京成立。1959～1968年首次创业：承担国家重大科研项目与开发任务，以及行业发展规划以及标准制定等工作，如“九大设备”的若干关键技术等。1969～1972年搬迁河南：1969年按照“战备疏散”的要求，机械科学研究院主体迁建河南漯河，成立“漯河机械研究所”；1972年因发展需要，改迁河南郑州，成立郑州机械研究所。1973～1998年二次创业：先后隶属于国家机械工业委员会、机械电子工业部、机械工业部；1981年4月罗干由铸造室主任升任副所长，同年经国务院批准具备硕士学位授予权；1985年“葛洲坝二、三江工程及其水电机组项目”荣获国家科技进步特等奖。1999～2016年发展壮大：1999年转企改制，隶属于国资委中国机械科学研究总院；2008年被河南省首批认定为“高新技术企业”；2011年获批组建新型钎焊材料与技术国家重点实验室；2014年被工信部认定为“国家技术创新示范企业”；历经十多年开发出填补国内外空白的大型齿轮齿条试验装备，完成了对三峡升船机齿条42.2万次应力循环次数的疲劳寿命试验测试；营业收入从几千万发展到近6亿；2017年至今协同发展：2017年经公司制改制，更名为郑州机械研究所有限公司，一以贯之地坚持党对国有企业的领导，充分发挥党委把方向、管大局、保落实的领导作用；一以贯之地建立现代企业制度，持续推进改革改制，努力实现以高质量党建引领郑机所高质量发展。']\n"
     ]
    }
   ],
   "source": [
    "question = '2024年8月11日清晨，父亲与孩子以及自行车队在容城县南拒马河右堤附近的路段骑行。该路段尚未正式通车，但已成为当地居民晨骑的热门地点。在骑行过程中，12岁孩子骑行速度一度达到37公里/小时，并在骑行中喊出“慢一点”。不幸的是，在一次变道中孩子不慎摔倒，倒在了对面的机动车道上，随即遭到对向行驶的汽车碾压。涉事汽车的行车记录仪显示，事故发生时汽车的行驶速度约为52公里/小时。请分析该案件的责任方。'\n",
    "print('> Question:', question)\n",
    "\n",
    "context = index.query(question)\n",
    "print('> Context:', context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-14T06:41:14.146316Z",
     "iopub.status.busy": "2024-08-14T06:41:14.145956Z",
     "iopub.status.idle": "2024-08-14T06:41:14.152509Z",
     "shell.execute_reply": "2024-08-14T06:41:14.151918Z",
     "shell.execute_reply.started": "2024-08-14T06:41:14.146293Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义大语言模型类\n",
    "class LLM:\n",
    "    \"\"\"\n",
    "    class for Yuan2.0 LLM\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_path: str) -> None:\n",
    "        print(\"Creat tokenizer...\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path, add_eos_token=False, add_bos_token=False, eos_token='<eod>')\n",
    "        self.tokenizer.add_tokens(['<sep>', '<pad>', '<mask>', '<predict>', '<FIM_SUFFIX>', '<FIM_PREFIX>', '<FIM_MIDDLE>','<commit_before>','<commit_msg>','<commit_after>','<jupyter_start>','<jupyter_text>','<jupyter_code>','<jupyter_output>','<empty_output>'], special_tokens=True)\n",
    "\n",
    "        print(\"Creat model...\")\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.bfloat16, trust_remote_code=True).cuda()\n",
    "\n",
    "        print(f'Loading Yuan2.0 model from {model_path}.')\n",
    "\n",
    "    def generate(self, question: str, context: List):\n",
    "        if context:\n",
    "            prompt = f'背景：{context}\\n问题：{question}\\n请基于背景，回答问题。'\n",
    "        else:\n",
    "            prompt = question\n",
    "\n",
    "        prompt += \"<sep>\"\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"].cuda()\n",
    "        outputs = self.model.generate(inputs, do_sample=False, max_length=1024)\n",
    "        output = self.tokenizer.decode(outputs[0])\n",
    "\n",
    "        print(output.split(\"<sep>\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-08-14T06:41:16.359794Z",
     "iopub.status.busy": "2024-08-14T06:41:16.359436Z",
     "iopub.status.idle": "2024-08-14T06:41:44.203585Z",
     "shell.execute_reply": "2024-08-14T06:41:44.202978Z",
     "shell.execute_reply.started": "2024-08-14T06:41:16.359771Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Create Yuan2.0 LLM...\n",
      "Creat tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creat model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./IEITYuan/Yuan2-2B-July-hf were not used when initializing YuanForCausalLM: ['model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.10.self_attn.rotary_emb.inv_freq', 'model.layers.11.self_attn.rotary_emb.inv_freq', 'model.layers.12.self_attn.rotary_emb.inv_freq', 'model.layers.13.self_attn.rotary_emb.inv_freq', 'model.layers.14.self_attn.rotary_emb.inv_freq', 'model.layers.15.self_attn.rotary_emb.inv_freq', 'model.layers.16.self_attn.rotary_emb.inv_freq', 'model.layers.17.self_attn.rotary_emb.inv_freq', 'model.layers.18.self_attn.rotary_emb.inv_freq', 'model.layers.19.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.20.self_attn.rotary_emb.inv_freq', 'model.layers.21.self_attn.rotary_emb.inv_freq', 'model.layers.22.self_attn.rotary_emb.inv_freq', 'model.layers.23.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.9.self_attn.rotary_emb.inv_freq']\n",
      "- This IS expected if you are initializing YuanForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing YuanForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of YuanForCausalLM were not initialized from the model checkpoint at ./IEITYuan/Yuan2-2B-July-hf and are newly initialized: ['model.rotary_pos_emb.inv_freq']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Yuan2.0 model from ./IEITYuan/Yuan2-2B-July-hf.\n"
     ]
    }
   ],
   "source": [
    "print(\"> Create Yuan2.0 LLM...\")\n",
    "# model_path = './IEITYuan/Yuan2-2B-Mars-hf'\n",
    "model_path = './IEITYuan/Yuan2-2B-July-hf'\n",
    "llm = LLM(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-08-14T06:41:44.205036Z",
     "iopub.status.busy": "2024-08-14T06:41:44.204737Z",
     "iopub.status.idle": "2024-08-14T06:41:53.078545Z",
     "shell.execute_reply": "2024-08-14T06:41:53.077991Z",
     "shell.execute_reply.started": "2024-08-14T06:41:44.205015Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Without RAG:\n",
      " 根据提供的信息，该案件的责任方可以是以下几个方面：\n",
      "1. 自行车骑行者：根据描述，12岁的孩子在骑行过程中喊出“慢一点”，这表明他可能对自行车的速度和安全有更高的要求。因此，自行车骑行者可能需要承担一定的责任。\n",
      "2. 自行车骑行者与自行车队：自行车队在骑行过程中可能没有遵守交通规则，例如超速、闯红灯等，这可能导致事故的发生。因此，自行车骑行者和自行车队可能需要承担一定的责任。\n",
      "3. 自行车骑行者与道路条件：道路条件也可能对事故的发生产生影响。如果道路条件不良，例如路面湿滑、坑洼不平等，自行车骑行者可能需要承担一定的责任。\n",
      "4. 自行车骑行者与车辆：如果自行车骑行者在变道时不慎摔倒，并被对向行驶的汽车碾压，那么自行车骑行者可能需要承担一定的责任。\n",
      "综上所述，该案件的责任方可能包括自行车骑行者、自行车队、道路条件和车辆。具体责任的分配需要根据具体情况和证据来确定。<eod>\n",
      "> With RAG:\n",
      " 根据提供的背景信息，无法确定该案件的责任方。<eod>\n"
     ]
    }
   ],
   "source": [
    "print('> Without RAG:')\n",
    "llm.generate(question, [])\n",
    "\n",
    "print('> With RAG:')\n",
    "llm.generate(question, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
